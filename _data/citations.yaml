# DO NOT EDIT, GENERATED AUTOMATICALLY

- id: arXiv:2502.04949
  title: Does Unsupervised Domain Adaptation Improve the Robustness of Amortized Bayesian
    Inference? A Systematic Evaluation
  authors:
  - Lasse ElsemÃ¼ller
  - Valentin Pratz
  - Mischa von Krause
  - Andreas Voss
  - Paul-Christian BÃ¼rkner
  - Stefan T. Radev
  publisher: arXiv
  date: '2025-05-21'
  link: https://arxiv.org/abs/2502.04949
  type: paper
  description: 'Neural networks are fragile when confronted with data that significantly
    deviates from their training distribution.  This is true in particular for simulation-based
    inference methods, such as neural amortized Bayesian inference (ABI),  where models
    trained on simulated data are deployed on noisy real-world observations. Recent
    robust approaches employ  unsupervised domain adaptation (UDA) to match the embedding
    spaces of simulated and observed data. However, the lack of  comprehensive evaluations
    across different domain mismatches raises concerns about the reliability in high-stakes
    applications.  We address this gap by systematically testing UDA approaches across
    a wide range of simulation gaps in silico and practice.  We demonstrate that aligning
    summary spaces between domains effectively mitigates the impact of unmodeled phenomena
    or noise.  However, the same alignment mechanism can lead to failures under prior
    misspecifications - a critical finding with practical  consequences. Our results
    underscore the need for careful consideration of misspecification types when using
    UDA to increase  the robustness of ABI.

    '
  buttons:
  - type: source
    link: https://github.com/bayesflow-org/NPE-UDA
  tags:
  - simulation-based inference
  - robustness
  - unsupervised domain adaptation
  - Bayesian inference
  plugin: sources.py
  file: sources.yaml
